\documentclass[12pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{}
  \pretitle{\vspace{\droptitle}}
  \posttitle{}
  \author{}
  \preauthor{}\postauthor{}
  \date{}
  \predate{}\postdate{}

\usepackage{float} \renewcommand{\thepage}{S\arabic{page}}
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thefigure}{S\arabic{figure}}

\begin{document}

\vspace{2cm}

\begin{center}
 \textbf{Supplementary Material: Article title here}
 
Authors: Easton R. White$^{1*}$
\vspace{3 mm}

Address: \\ \emph{$^1$ Center for Population Biology, University of California-Davis, Davis, California 95616 USA}

*Corresponding author: eawhite@ucdavis.edu

June 22, 2017
 \end{center}

\vspace{2cm}

This supplementary material includes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Detailed example of subsampling and power calculations
\item
  Additional figures
\item
  Figures and results from other questions of interest
\item
  Additional references
\end{enumerate}

Code for all the figures and tables can be found at
\href{https://github.com/erwhite1}{}.

\vspace{2cm}

\subsection{Detailed example of subsampling and power
calculations}\label{detailed-example-of-subsampling-and-power-calculations}

Here, we illustrate in detail how we performed the subsampling and power
calculations for a specific population. As an example, we examine a
35-year time series of (). Simple linear regression indicates a
significant decline for this population with a blank and blank. We
assume that this significant decline over 35 years is in fact the ``true
trend``. In statistical jargon, the 35-year trend is an effect that is
actually present. We can then use this as a benchmark to see if
subsamples of the time series show a similar result.

We first extract all contiguous subsamples of the time series. This
leads to 34 two-year subsamples, 33 two-year subsamples, and so forth
until a single 35-year subsample. We can call each set of subsamples, of
the same length, a set. For each subsample, we conduct linear regression
and extract model coefficients and p-values. Then, the fraction of
subsamples within a set that show significant trends (signfiiant slope
coefficient) is the statistical power. It is important to note that we
only consider subsamples to be significant if they are significant in
the same direction as the complete 35-year time series.

We can then plot statistical power as a function of time series length.
As expected, we can see that power increases with the more years that
are sampled.

Then, we determine an appropriate level of statistical power that we
find acceptable. Traditionally, this has been at 0.8, however, this is
purely historical. Statisical power of 0.8 implies\ldots{}

With statistical power of 0.8, we then determine the minimum time series
length (\(t_min\)) required to achieve that level of statistical power.
Here, \(t_min\) is the first point as which all points to the right are
above 0.8.

\subsection{Additional results from the main
manuscript}\label{additional-results-from-the-main-manuscript}

In the main manuscript, we examined the minimum time required to detect
a significant trend in abundance over time using linear regression. As
detailed in the main manuscript the minimum time required was around 15,
but there was a wide distribution. Therefore, we were interested in
potential explanatory variables of the minimum time required. In the
main manuscript, we examined characteristics of the time series itself,
like variability, autocorrelation, and the trend in abundance over time.
Here, we combined our time series database with a database on life
history characteristics of amniotes from (cite other database here).
There was life history information available for 547 populations
representing 315 different species, all of which were in the Aves class.

We then correlated minimum time required for each population with its
corresponding life history characteristics. In figure
\ref{fig:biological_correlates} we examined miminmum time required
versus generation length (years), litter size (n), adult body mass
(grams), maximum longevity (years), egg mass (grams), and incubation
(days). None of these variables had much explanatory power in accounting
for the variance in the minimum time required. see table
\ref{table:model_output}\}

\begin{figure}[htbp]
\centering
\includegraphics{supp_mat_draft_files/figure-latex/unnamed-chunk-3-1.pdf}
\caption{Mimimum time required versus (a) generation length (years), (b)
litter size (n), (c) adult body mass (grams), (d) maximum longevity
(years), (e) egg mass (grams), and (f) incubation (days). The lines in
each plot represent the best fit line from linear
regression.\label{fig:biological_correlates}}
\end{figure}

\pagebreak

In the main text, we explained how the minimum time required strongly
correlated with the trend strength, temporal autocorrelation, and
variance in population size. Here we use a generalized linear model
framework with a Poisson error structure to determine drivers of the
minimum time required. In figure, \ref{fig:poisson_model} we show a set
of residual plots for the regression. We then show the coefficient
estimates and levels of significance in table \ref{table:model_output}.

\begin{figure}[htbp]
\centering
\includegraphics{supp_mat_draft_files/figure-latex/poisson_model-1.pdf}
\caption{Output of poisson regression\ldots{}\label{fig:poisson_model}}
\end{figure}

\begin{longtable}[]{@{}lrrrr@{}}
\caption{Stuff here\label{table:model_output}}\tabularnewline
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endfirsthead
\toprule
& Estimate & Std. Error & z value &
Pr(\textgreater{}\textbar{}z\textbar{})\tabularnewline
\midrule
\endhead
(Intercept) & 3.7141297 & 0.0274350 & 135.379203 &
0.0000000\tabularnewline
abs\_overall\_trend & -104.4974288 & 3.0997732 & -33.711314 &
0.0000000\tabularnewline
autocorrelation & -0.4905888 & 0.0431062 & -11.380936 &
0.0000000\tabularnewline
variance & 18.7756472 & 0.6409982 & 29.291262 & 0.0000000\tabularnewline
gen\_len & 0.0053584 & 0.0025995 & 2.061352 & 0.0392695\tabularnewline
\bottomrule
\end{longtable}

Our model with trend strength, autocorrelation, variance, and generation
length accounted for 72.55\% of the variation in the minimum time
required (Table \ref{table:model_output}). However, we also found trend
strength and variance to be strongly correlated with one another.
Therefore, we ran two additional models with either trend strength or
variance, but not both together. This resulted in lower explained
deviance (analogue to \(R^2\)) of 53.08\% and 45.04\%, respectively.

\pagebreak

\subsection{Results from other questions of
interest}\label{results-from-other-questions-of-interest}

\subsubsection{Simulations with more complicated population
model}\label{simulations-with-more-complicated-population-model}

In the main text, we showed how a simple population model could be
simulated repeatidly to estimate the power obtained with time series of
increasing length. The model in the main text simulated linear
population growth with only a slope coefficient, y-intercept, and noise
parameter required. This model is purely phenemilogical and does not
include any species life history. Here, we use the same routine as the
main text, but simulate from a more biologically-realistic population
model, the (MODEL NAME HERE):

\begin{equation}
    y = x
  \end{equation}

We simulate this model repetively for different lengths of time series.
Statistical power is the fraction of time series of a set length that
showed signicant trends in abundance, given a true trend in abundance.
\emph{How do I determine significance here? Through linear regression
again, or do I look at non-zero estimation of the parameter values?}

\subsubsection{Empirical approach with more complicated population model
(use model similar to de Valpine
work?)}\label{empirical-approach-with-more-complicated-population-model-use-model-similar-to-de-valpine-work}

\subsubsection{Growth rate calculations}\label{growth-rate-calculations}

Instead of detecting a trend over time with linear regression, we could
also calculate the geometric growth rate of the population. In figure
\ref{fig:growth_rate}, we show how to calculate growth rates for
subsamples of a time series. First, we created subsamples of each
possible length from the full 35 year time series, as we did in the main
next. Next, we calculated the mean and standard deviation of growth
rates for each possible time series length (Fig.
\ref{fig:growth_rate}b). Lastly, we calculated the percent error
\(\mbox{percent error} = 100 \times \left| \frac{\mbox{observed} - \mbox{theoretical}}{\mbox{theoretical}} \right|\)
between the mean of each time series length (observed) and the overall
population growth rate (theoretical). In Fig. \ref{fig:growth_rate}c),
we show the percent error as a function of time series length. Here we
define the minimum time required as the minimum number of years to
achieve less than 20\% error.

\begin{verbatim}
## Loading required package: plyr
\end{verbatim}

\begin{figure}[htbp]
\centering
\includegraphics{supp_mat_draft_files/figure-latex/unnamed-chunk-5-1.pdf}
\caption{Example of calculating minimum time required for growth rate
estimation. (a) abundance over time, (b) mean and standard deviation of
growth rate for subsamples of entire time series, and (c) the percent
error between mean estimated growth rate and the true longterm growth
rate. The vertical bar denotes the minimum time required to estimate
growth rate within 10\% error.\label{fig:growth_rate}}
\end{figure}

We applied the same calculations to 1032 populations, as we did in the
main text. We then obtain a distribution of the minimum time required to
measure the ``true" longterm growth rate (Fig.
\ref{fig:min_time_growth_dist}). We see a bimodal distribution with many
populations required 30+ years to estimate the longterm growth rate. The
large number of short year required is due to cases where the entire
time series is consistently increasing or decreasing at the same rate.

\clearpage 

\subsubsection{Using Generalized additive model to identify significant
trends}\label{using-generalized-additive-model-to-identify-significant-trends}

In the main text, we examined the minimum time required to identify a
trend in abundance via linear regression. This approach allowed us to
identify increases or decreases, but a linear model may not always be a
good fit. Generalized additive models (GAMs) are more general than
general linear models and allow more flexible. GAMs are models where a
response variable depends on unknown smooth functions of explanatory
variables. GAMs, therefore, can identify relationships between response
variables and explantory variables that are non-linear and perhaps more
complicated. The downside of GAMs is they typically require more data
and are also prone to overfitting (citations).

Here, we conduct the same analyses in the main text, but instead
calculate the minimum time series required to detect trends over time
according to a GAM model. We hypothesize that GAMs should require less
time to detect a trend as they are more flexible than linear regression.
We provide an example that shows statistical power increases with more
time sampled (Fig. \ref{fig:gam_example}).

\begin{figure}[htbp]
\centering
\includegraphics{supp_mat_draft_files/figure-latex/unnamed-chunk-7-1.pdf}
\caption{results here from GAM.\label{fig:gam_example}}
\end{figure}

We then fit GAM models for XX populations. We found\ldots{} (Fig.
\ref{fig:gam_result}). This is shorter/longer than the main text
question.

\subsubsection{Minimum time to detect density-dependence in time
series}\label{minimum-time-to-detect-density-dependence-in-time-series}

For decades, the importance of density-dependence in natural populations
has been an important question in ecology (citations). To address this
question, \citet{Knape2012} used data from the Global Population
Dynamics Database \citep{GPDD2010}. They fitted 627 time series with a
Gompertz population model and found evidence for density-dependence in
45\% of the time series. Each time series in their database contained at
least 15 datapoints, and ranged from 15 to 157. A follow up question to
their work would be, what time series length is required to confidently
estimate density-dependence.

\clearpage
\#\#\# References

\bibliography{White_bib.bib}


\end{document}
