\documentclass[12pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{}
  \pretitle{\vspace{\droptitle}}
  \posttitle{}
  \author{}
  \preauthor{}\postauthor{}
  \date{}
  \predate{}\postdate{}

\usepackage{float}
\usepackage{setspace}\doublespacing \usepackage{lineno}
\usepackage[round]{natbib} \bibpunct[; ]{(}{)}{,}{a}{}{;} \linenumbers

\begin{document}

Running head: \vspace{3 mm}

Title: Your time series is (probably) too short \vspace{7 mm}

Author(s): \textsc{Easton R. White$^{1,2}$} \vspace{3 mm}

Addresses:\emph{$^1$ Center for Population Biology, University of California-Davis, Davis, California 95616 USA}
\vspace{3 mm}

\(^2\)Corresponding author:
\href{mailto:eawhite@ucdavis.edu}{\nolinkurl{eawhite@ucdavis.edu}}
\vspace{3 mm}

Number of words: X,XXX (less than 4,000 words or 20 pages) \vspace{3 mm}

To be submitted to: \emph{Biological Conservation} (Short Communication)
\vspace{3 mm}

Available as a preprint at: www.peerj.com \vspace{3 mm}

Keywords: ecological time series, experimental design, monitoring, power
analysis, statistical power, sampling design

\vspace{3 mm}

\pagebreak 

\linenumbers

\section{Abstract}\label{abstract}

Long-term census data is necessary to better understand ecological
processes and make management decisions. However, census data is often
expensive, requiring a lot of people-hours and equipment. Little work
has addressed the question, when is a time series of census data long
enough to address a question of interest? Here, we explore two
approaches to address this question: through simulations and through an
empirical approach. I specifically determine the minimum time series
length required to estimate significant increases or decreases in
population abundance. Importantly, I examine the ability to detect a
trend with a set level of statistical power, which is often neglected in
ecological time series analyses. Using a simulation approach, we
demonstrate how the minimum time series length required increases with
weaker trends in abundance and with higher population variability. In
addition, we examine 868 populations of vertebrate species to determine
the minimum time required to detect changes in their abundance. We show
that 10-15 years of continuous monitoring are required in order to
achieve a high level of statistical power. Similar to
simulation-approaches, the minimum time required for field census data
strongly depends on trend strength, population variability, and temporal
autocorrelation. These results point to the importance of sampling
populations over long periods of time. Most studies, especially those
less than 10-15 years, are probably underpowered and potentially
misleading.

\section{Introduction}\label{introduction}

Observational studies and population censuses have become a cornerstone
of modern ecological research and conservation biology (Magurran et al.
2010). Longterm data is necessary to both understand population dynamics
and to assess extinction risk of species. Even though many time series
may now be considered ``longterm'', most are still short (i.e.~less than
X years). \emph{I could have statistic on how long is considered
``longterm'' in papers}. Time series are typically short for a variety
of reasons. They are often coupled with an experiment, which may only
last a couple of years. In addition, short funding cycles make it
difficult to examine populations over longer periods of time
(citations). There are, of course, notable exceptions including the Isle
Royale study, Iowa corn study, cod, lynx-hair, and many others
(citations).

Naturally, one might ask, how long of a time series is actually
necessary? This question has important implications for both research
and management. Scientifically, we need to know the time series length
required to address a specific question. Too short of a time series may
lead to wrong conclusions given large natural year-to-year variability
(citations). From a management perspective, it is important to
understand when a trend in abundance over time is actually meaningful or
not. The IUCN Red List Categories and Criteria suggest under Criterian
A2, a species qualifies as vulnerable if it has experienced a 30\%
decline over 10 years, or 3 generations (IUCN 2012). For both scientific
and management questions, because sampling is typically expensive, we do
not want to sample for longer than is neccessary (Gerber, DeMaster, and
Kareiva 1999).

In determining the number of samples required for a particular
experiment four quantities are intricately linked: statistical power
(1-\(\beta\)), effect size, \(\alpha\), and sample size (Legg and Nagy
2006). The exact relationship between these quantities depends on the
specific statistical test. Formally, statistical power (\(1-\beta\)) is
one minus the probability of a type II error (\(\beta\)), or false
negative. In other words, it is a measure of how well you could detect a
trend given it is actually significant. Prior to an experiment, one
could set appropriate levels of power, significance threshold
(\(\alpha\)), and the effect size to estimate the sample size required
for the experiment. This approach, however, is not straight-forward for
a time series, or more complicated scenarios (P. C. D. Johnson et al.
2015), as data points are clearly non-independent.

For time series data, two general approaches can be used. First, as can
be done with experimental data, we can relax the definition of
statistical power (cite Bolker). Instead of using classic statistical
tests (e.g.~t-test), and corresponding formulas for determinig sample
size, simulation approaches can be used (Gerrodette 1987). Simple
population models can be simulated with parameter values corresponding
to a population of interest. Out of a large number of simulations, power
can be calculated as the fraction of simulations that meet some
criteria. The specific criteria depend on the question at hand. Then
time series simulations of different lengths are run to determine the
minimum time series length required to be confident that you will be
able to answer your question (cite Bolker). In addition to using
simulated data, empirical time series can also be used. We usually do
not have multiple replicates of similar populations, but we can
subsample an empirical time series (cite). Subsamples of different
lengths can then be evaluated to see which fraction of subsamples meet
some criteria, again a measure of statistical power. Similar to the
simulation approach, we can use these measures of power to determine the
minimum time series required for a particular question of interest.

Past work has investigated questions related to the minimum time series
required to estimate trends in population size over time (Giron-Nava et
al. 2017). For example, Rhodes and Jonzen (2011) examined the optimal
allocation of effort between spatial and temporal replicates. Using
simple populations models, they found that the allocation of effort
depends on environmental variation, spatial and temporal
autocorrelation, and observer error. Rueda-Cediel et al. (2015) also
used a modeling approach, but parameterized it for a threatened snail,
\emph{Tasmaphena lamproides}. They found that for this short-lived
organims, that 15 years was adequate to assess longterm trends in
abundance. However, these studies, and other past work, have focused
either on theoretical aspects of monitoring design or focused on single
species.

In this paper, we use both simulations and a database of empirical time
series to determine the minimum number of years required to address
various questions. More specifically, we estimate the minimum time
series length required to asssess longterm changes in abundance via
simple linear regression.

\section{Methods}\label{methods}

\subsection{Simulation approach}\label{simulation-approach}

One approach to determining the minimum time series length needed is
through repetitive simulations of a population model (Gerrodette 1987).
This is the same approach one might use in sample size calculations for
any experimental design too complicated for simple power analyses (P. C.
D. Johnson et al. 2015) (and cite Bolker). We only briefly discuss this
approach as it has been desribed elsewhere (citations). Essentially, we
take a stochastic population model and simulate it for a number of years
repetitively. We can then determine the minimum time series required to
achieve designed levels of significance and power for a particular
question. This approach requires us to determine values for our model
parameters (e.g.~growth rate). As an example, we can take the following
population model for population size \(N\) at time \(t\): \[
N(t + 1) = N(t) + r(t) \mbox{ with } r(t) \sim N(\mu, \sigma)
\] where \(\epsilon\) is a normally-distributed random noise term with
mean \(\mu\) and standard deviation \(\sigma\). The rate of growth \(r\)
is also the trend strength of increase or decrease.

By simulating this model repetitively for different lengths of time, we
can determine the minimum time series required. Here statistical power
is simply the fraction of simulations with significant trends in
abundance from simple linear regression. Then, the minimum time required
is the minimum time required to obtain statistical power above some
pre-determined threshold (historically at 0.8).

In Fig. \ref{fig:theoretical_approach}a, a number of simulated time
series are shown for a set number of time periods (\(t=40\)). It is
clear that statistical power increases quickly with increases in length
of time sampled (Fig. \ref{fig:theoretical_approach}b). Once power is
greater than 0.8 (the dotted line), that is the minimum time required
(\(T_{min}\)).

\begin{figure}[htbp]
\centering
\includegraphics{manuscript_draft_files/figure-latex/unnamed-chunk-1-1.pdf}
\caption{(a) example of simulated time series for 40 time periods and
(b) statistical power versus the simulated time series length. The
horizontal, dashed line is our desired statistical power of 0.8. The
vertical, dashed line is the minimum time required to achieve our
desired statistical power. (c) Minimum time required for different
values of the trend strength (\(r\)) and (d) minimum time required for
different levels of population variability
(\(\sigma\)).\label{fig:theoretical_approach}}
\end{figure}

\subsection{Data source}\label{data-source}

We use a database of 2444 population time series compiled in (Keith et
al. 2015). The data is originally from the Global Population Dynamics
Database (NERC Centre for Population Biology 2010). We filtered out
short time series (less than 35 years), and those with missing data, and
were left with 878 time series. The database includes information on 478
vertebrate species with a focus on mammals, birds, and fish. The
database also includes information on generation length and census
specifications. For each time series, we also calculated variables of
interest like variance in population size, longterm trend in abundance
(slope coefficient from simple linear regression), and temporal
autocorrelation. Lastly, we also calculated the minimum number of years
required (10 years or 3 generations) under IUCN Red List Criterian A2 to
classify a species as vulnerable (IUCN 2012).

For a subset of populations in the database (\(n =\) 547), we were able
to connect a database on biological characteristics (\textbf{cite
database here}) like body size and generation length. All 547
populations are within the Aves class. In the supplementary material, we
explore how the minimum time required does not strongly correlate with
any biological characteristics.

\subsection{Empirical approach}\label{empirical-approach}

We assume that each time series in our database is long enough to
include all necessary information (e.g.~variability) about the
population. In other words, each time series is a representative sample.
We first take all possible contiguous subsamples of each time series.
For example, a time series of 40 years would have 39 possible contiguous
subsamples of length 2, 38 possible contiguous subsamples of length 3,
and continuing until 1 possible contiguous subsample of length 40
(Gerber, DeMaster, and Kareiva 1999, Giron-Nava et al. (2017)). Then we
determined the \(T_{min}\) required to be confident (i.e.~have high
enough statistical power) in an estimate of the slope coefficient from
linear regression. Therefore, we run a linear regression for each
subsampled time series. Then, we determine the fraction of subsamples of
a particular length that have estimated slope coefficients which are
statistically different from zero given the longterm, or ``true``, time
series also has a significant slope. This is a measure of statistical
power (often denoted as \(1- \beta\), where \(\beta\) is the probability
of a type II error). Lastly, we determine which subsample length is
required to guarantee we have above a certain threshold of statistical
power, which we will assume is 0.8 by convention (citation). A power of
0.8 would imply that given a trend exists, there is a 0.8 probability of
detecting the trend. Complementary, there would be a 0.2 probability of
a false negative.

\begin{figure}[htbp]
\centering
\includegraphics{manuscript_draft_files/figure-latex/unnamed-chunk-4-1.pdf}
\caption{(a) Population size of Harp Seals over time. The line is the
best fit line from linear regresssion. (b) Statistical power for
different subsets of the time series in panel
a.\label{fig:empirical_approach_example}}
\end{figure}

We also examine how minimum time series calculations changed depending
on the question of interest. In the supplementary material, we show how
to make similar calculations to determine the minimum time series
required to estimate overall population growth rate, the variability in
population size, and future extinction risk. Again, we took subsamples
of time series data to determine \(T_{min}\) for each of these
questions.

\section{Results}\label{results}

We determined the minimum time series length required to address a
particular question of interest. More specifically we asked, what is the
minimum time series length required to determine, via linear regression,
the longterm trend in population abundance? The minimum time series
length required is that which had high enough statistical power. We
investigated this question through two approaches: simulation-based and
empirical analyses. We briefly desribe results from the simulation
approach and then discuss our emprirical approach.

\subsection{Simulation approach}\label{simulation-approach-1}

We constructed a general population model where the trend over time
could be a model parameter. We chose a simple model, but any other
population model could be used. The specific model choice should be
tailored to the population of interest. We then ran simulated time
series of different lengths. From these simulations we determined the
minimum time series length required to achieve a certain level of power
(which we set to 0.8). We were also able to alter the parameter values
(trend strength and population variability) of the population model to
see how this altered \(T_{min}\).

In line with past work, we found the \(T_{min}\) increases (i.e.~more
time is required) with decreases in trend strength and with increases in
variability (citation).

\subsection{Empirical test}\label{empirical-test}

\begin{figure}[htbp]
\centering
\includegraphics{manuscript_draft_files/figure-latex/unnamed-chunk-5-1.pdf}
\caption{Distribution of the minimum time required in order to detect a
significant trend (at the 0.05 level) in abundance given power of
0.8.\label{fig:min_time_dist}}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{manuscript_draft_files/figure-latex/unnamed-chunk-6-1.pdf}
\caption{Minimum time required to estimate change in abundance
correlated with (a) trend strength (absolute value of slope coefficient
estimated from linear regression), (b) population variance (interannual
variability in population size), and (c) temporal
autocorrelation.\label{fig:correlates}}
\end{figure}

We examined a database of 878 separate population time series
representing 478 species. This database consists of species with a
variety of life history characteristics. We limited our analyses to
populations with at least 35 years of continuous sampling.

Across all the populations we examined, we found an average minimum time
series length required (\(T_{min}\)) of 16.5 (\(\sigma\)=8.4), with a
wide distribution (Fig. \ref{fig:min_time_dist}). In addition, as
expected based on theoretical results (cite papers), the minimum time
series length required is strongly correlated with trend strength,
population variance, and autocorrelation (Fig \ref{fig:correlates}).
Using a generalized linear model, with a Poisson error structure, all
three of these explanatory variables were significant and had large
effect sizes (see Fig. SX). Combined, trend strength, population
variance, and autocorrelation account for about 72.6 of the explained
deviance, which is similar to \(R^2\) (Zuur et al. 2009), in minimum
time series length required.

We also examined a subset of populations where more explanatory
variables were known (e.g.~body mass, longevity, location). None of
these explanatory variables were predictive of the minimum time series
length required (\textbf{supp mat}). Some differences if \(T_{min}\) did
occur between biological class (\textbf{supp mat}), but this can be
attributed to the amount populations are known to fluctuate (i.e.~the
variability in population size).

\subsection{Questions in the appendix}\label{questions-in-the-appendix}

Describe some of the results that we include in the appendix

\section{Discussion}\label{discussion}

We explored two different approaches to estimate the minimum time series
length required to address a particular question of interest. We
specifically asked, what is the minimum time series length required to
determine longterm changes in abundance using linear regression? The
simulation-based approach has been suggested by others, especially in
situations more complicated than that suited for classic power analysis
(Gerrodette 1987, Johnson2015). Our simulations support past work that
longer time series are needed when the trend strength (i.e.~rate of
increase or decrease) is weak or when population variability is high
(Gerrodette 1987).

Here, we focus on a empirical approach to estimate the minimum time
series length requried to assess changes in abundance over time. We
examined long time series and then subsampled each to determine the
minimum time required to achieve a desired level of significance and
power for linear regression. Statistical power is important as it
provides on information as to the neccessary samples required to
dertermine a significant trend (Legg and Nagy 2006). We found that for
878 populations, at least 10-15 years of continuous monitoring were
neccessary (Fig. \ref{fig:min_time_dist}). This timeframe is in line
with past work on a short-lived snail species (Rueda-Cediel et al. 2015)
and a long-lived whale species (Gerber, DeMaster, and Kareiva 1999). In
line with theoretical predictions (citations), we also found \(T_{min}\)
was strongly correlated with the trend strength, variability in
population size, and temporal autocorrelation (Fig.
\ref{fig:correlates}). Against our prior expectations, we also found
that \(T_{min}\) did not correlate with any biological variables of
interest (cite figure or supp mat). We initially hypothesized that
species with longer lifespans or generation times may require a longer
sampling period. Our result could have result of at least two effects.
First, the database we used may not include a diverse enough set of
species with different life history traits. Second, the question we
poised, whether a population is increasing or decreases, is only worried
about population surveys. Therefore, biological variables may be more
important if the question itself was different. ANOTHER SENTENCE HERE

There has also been interest in determining the minimum time series
length in the bird community (Hatch 2003, ({\textbf{???}}), Seavy and
Reynolds (2007)). Hatch (2003) used seabird monitoring data to estimate
the minimum time needed to achieve appropriate levels of power. He found
that the minimum time required ranged between 11 and 69 years depending
on species, trend strength, and study design. Similarly,
({\textbf{???}}) recommended a standard of 80\% power to detect a 50\%
decline over 20 years in landbird populations. They found that only
about 42\% of populations in the Breeding Bird Survey met their
criteria. Seavy and Reynolds (2007) asked whether statistical power was
even a useful framework for assessing longterm population trends. They
used 24 years of census data on Red-tailed Tropicbirds
(\emph{Phaethon rubricauda}) in Hawaii and showed that to detect a 50\%
decline over 10 years almost always resulting in high statistical power
(above 0.8). Therefore, they cautioned against only using power analyses
to design monitoring schemes and instead argued for precision based
metrics ..

An important related question, is the optimal allocation of sampling
effort in space versus time (citations). In a theoretical investigation
of this question, Rhodes and Jonzen (2011) found that the optimal
allocation of sampling depended strongly on temporal and spatial
autocorrelation. If spatial population dynamics were highly correlated,
then it was better to sample more temporally, and vice versa. Our work
supports this idea as populations with strong temporal autocorrelation
needed less years of sampling (cite figure here). Morrison and Hik
(2008) also studied the optimal allocation of sampling effort in space
versus time, but used emprical data from a longterm census of the
collared pika (\emph{Ochotona collaris}) found in the Yukon. They
estimated longterm growth rates among three subpopulations over a
10-year period. They found that censuses less than 5 years may be
misleading and that extrapolating from one population to another, even
when nearby, may be difficult. Therefore, they argued more sampling
should be conducted spatially than temporally (Morrison and Hik 2008).

\subsection{Other questions addressed}\label{other-questions-addressed}

In the appendix we asked two additional questions to make estimates of
\(T_{min}\). First, we asked how many years of sampling are neccessary
to estimate a geometric growth rate?

\subsection{Limitations}\label{limitations}

Our work has some limitations in determining the minimum time series
length required. First, \(T_{min}\) depends strongly on the question of
interest. For our empirical approach, the subsampling of the full time
series allows for estimates of power, but the individual subsamples are
clearly not independent of one another. In addition, estimates of
\(T_{min}\) depend on chosen values of \(\alpha\) and \(\beta\) (see
appendix). In an ideal world, we would build a specific population model
parameterized for each population of interest. Then, model simulations
could be used to estimate the minimum time series reuqired to address a
specific question of interest. Clearly, this is not always practical,
especially if running analyses for a wide array of species as we do
here. In addition, our statistical models suggest that \(T_{min}\) does
not correlate with any biological variables of interest, at least for
the question of linear regression. Therefore, it is not possible to use
these results to predict \(T_{min}\) for another population, even if the
population is of a species with a similar life-history to one in our
database.

\subsection{Conclusions}\label{conclusions}

We use a database of 878 populations to determine the minimum time
series length required. We show that to identify longterm changes in
abundance, 10-15 years of continuos monitoring are required (Fig.
\ref{fig:min_time_dist}). In line with theoretical predictions, we also
show that \(T_{min}\) is strongly correlated with the overall trend in
abundance, variability in abundance, and the temporal autocorrelation
(Fig. \ref{fig:correlates}). Our work implies that for many populations,
census data less than 10-15 years are probably not reliable. This
stresses the importance of longterm monitoring programs. From both a
scientific and management perspective estimates of \(T_{min}\) are
important. If a time series is too short, we are likely to make
incorrect conclusions about longterm trends. In addition, a time series
that is too long may be a poor use of already limited funds (Gerber,
DeMaster, and Kareiva 1999). Future work can examine other species, with
a wider range of life history characteristics. In addition, similar
approaches can be used to determine the minimum time series length
required to address other questions.

\section{Supporting Information}\label{supporting-information}

In the supporting material, we provide an expanded methods sections,
additional figures, and additional analyses of other time series
questions. All code and data can be found at www.github.com/erwhite1

\section{Acknowledgements}\label{acknowledgements}

ERW was partially supported by a National Science Foundation Graduate
Fellowship. We would like to thank members of the Ecological Theory
group at the University of California, Davis for their insight. We would
also like to thank X anonymous reviewers for their helpful comments.

\section{References}\label{references}

\hypertarget{refs}{}
\hypertarget{ref-Gerber1999}{}
Gerber, L R, D P DeMaster, and P M Kareiva. 1999. ``Gray whales and the
value of monitering data in implementing the U.S. endangered species
act.'' \emph{Conservation Biology} 13 (5): 1215--9.

\hypertarget{ref-Gerrodette1987}{}
Gerrodette, Tim. 1987. ``A power analysis for detecting trends.''
doi:\href{https://doi.org/10.2307/1939220}{10.2307/1939220}.

\hypertarget{ref-Giron-Nava2017}{}
Giron-Nava, Alfredo, Chase C James, Andrew F Johnson, David Dannecker,
Bethany Kolody, Adrienne Lee, Maitreyi Nagarkar, et al. 2017.
``Quantitative argument for long-term ecological monitoring.''
\emph{Marine Ecology Progress Series} 572: 269--74.

\hypertarget{ref-Hatch2003}{}
Hatch, S A. 2003. ``Statistical power for detecting trends with
applications to seabirds monitoring.'' \emph{Biological Conservation}
111: 317--29.

\hypertarget{ref-IUCN2012}{}
IUCN. 2012. ``IUCN Red List Categories and Criteria: Version 3.1.''
doi:\href{https://doi.org/10.9782-8317-0633-5}{10.9782-8317-0633-5}.

\hypertarget{ref-Johnson2015}{}
Johnson, Paul C D, Sarah J E Barry, Heather M. Ferguson, and Pie Müller.
2015. ``Power analysis for generalized linear mixed models in ecology
and evolution.'' \emph{Methods in Ecology and Evolution} 6 (2): 133--42.
doi:\href{https://doi.org/10.1111/2041-210X.12306}{10.1111/2041-210X.12306}.

\hypertarget{ref-Keith2015}{}
Keith, David, H. Resit Akçakaya, Stuart H.M. Butchart, Ben Collen,
Nicholas K. Dulvy, Elizabeth E. Holmes, Jeffrey A. Hutchings, et al.
2015. ``Temporal correlations in population trends: Conservation
implications from time-series analysis of diverse animal taxa.''
\emph{Biological Conservation} 192. Elsevier B.V.: 247--57.
doi:\href{https://doi.org/10.1016/j.biocon.2015.09.021}{10.1016/j.biocon.2015.09.021}.

\hypertarget{ref-Legg2006}{}
Legg, Colin J, and Laszlo Nagy. 2006. ``Why most conservation monitoring
is , but need not be , a waste of time.'' \emph{Journal of Environmental
Management} 78: 194--99.
doi:\href{https://doi.org/10.1016/j.jenvman.2005.04.016}{10.1016/j.jenvman.2005.04.016}.

\hypertarget{ref-Magurran2010}{}
Magurran, Anne E, Stephen R Baillie, Stephen T Buckland, Jan Mcp Dick,
David A Elston, E Marian Scott, Rognvald I Smith, Paul J Somerfield, and
Allan D Watt. 2010. ``Long-term datasets in biodiversity research and
monitoring : assessing change in ecological communities through time.''
\emph{Trends in Ecology and Evolution} 25: 574--82.
doi:\href{https://doi.org/10.1016/j.tree.2010.06.016}{10.1016/j.tree.2010.06.016}.

\hypertarget{ref-Morrison2008}{}
Morrison, Sharn, and David S. Hik. 2008. ``When? Where? and for how
long? Census design considerations for an Alpine Lagomorpg, the Collared
pika.'' In \emph{Lagomorph Biology}, 103--13. Springer Berlin
Heidelberg.
doi:\href{https://doi.org/10.1007/978-3-540-72446-9}{10.1007/978-3-540-72446-9}.

\hypertarget{ref-GPDD2010}{}
NERC Centre for Population Biology, Imperial College. 2010. ``The Global
Population Dynamics Database Version 2.''

\hypertarget{ref-Rhodes2011}{}
Rhodes, Jonathan R., and Niclas Jonzen. 2011. ``Monitoring temporal
trends in spatially structured populations: how should sampling effort
be allocated between space and time?'' \emph{Ecography} 34 (6): 1040--8.
doi:\href{https://doi.org/10.1111/j.1600-0587.2011.06370.x}{10.1111/j.1600-0587.2011.06370.x}.

\hypertarget{ref-Rueda-Cediel2015}{}
Rueda-Cediel, Pamela, Kurt E Anderson, Tracey J Regan, Janet Franklin,
and M Regan. 2015. ``Combined Influences of Model Choice , Data Quality
, and Data Quantity When Estimating Population Trends.'' \emph{PLoSONE}
10 (7): e0132255.
doi:\href{https://doi.org/10.1371/journal.pone.0132255}{10.1371/journal.pone.0132255}.

\hypertarget{ref-Seavy2007}{}
Seavy, Nathaniel E., and Michelle H. Reynolds. 2007. ``Is statistical
power to detect trends a good assessment of population monitoring?''
\emph{Biological Conservation} 140 (1-2): 187--91.
doi:\href{https://doi.org/10.1016/j.biocon.2007.08.007}{10.1016/j.biocon.2007.08.007}.

\hypertarget{ref-Zuur2009}{}
Zuur, Alain F., Elena N. Ieno, Neil J. Walker, Anatoly A. Saveliev, and
Graham M. Smith. 2009. \emph{Mixed Effects Models and Extensions in
Ecology with R}. New York: Springer.

\section{Figures}\label{figures}

stuff here

\section{Supplementary material}\label{supplementary-material}


\end{document}
